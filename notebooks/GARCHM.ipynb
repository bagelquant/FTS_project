{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3810c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm, chi2\n",
    "import pandas as pd\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch\n",
    "from arch import arch_model\n",
    "from scipy.stats import jarque_bera, shapiro\n",
    "import os \n",
    "import numdifftools as nd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "id": "db2f5501",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def return_process(return_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    We need monthly returns at the end of each month\n",
    "\n",
    "    :param return_data: DataFrame with date as index, stocks as columns and close price as values\n",
    "    \"\"\"\n",
    "\n",
    "    return_data.index = pd.to_datetime(return_data.index, format='%Y%m%d')\n",
    "    return_data = return_data.sort_index()\n",
    "    return_data = return_data.ffill()\n",
    "    last_ = return_data.resample('ME').last()\n",
    "    first_ = return_data.resample('ME').first()\n",
    "    last_ = last_.sort_index()\n",
    "    first_ = first_.sort_index()\n",
    "    monthly_return = (last_ - first_) / first_ \n",
    "    monthly_return = monthly_return.ffill()\n",
    "    monthly_return = monthly_return.dropna(axis=0, how='all')\n",
    "    monthly_return = monthly_return.dropna(axis=1, how='any')\n",
    "    lower = monthly_return.quantile(0.01)\n",
    "    upper = monthly_return.quantile(0.99)\n",
    "    monthly_return = monthly_return.clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "    daily_return = return_data.pct_change()\n",
    "    daily_return = daily_return.ffill()\n",
    "    daily_return = daily_return.dropna(axis=0, how='all')\n",
    "    daily_return = daily_return.dropna(axis=1, how='any')\n",
    "    lower = monthly_return.quantile(0.01)\n",
    "    upper = monthly_return.quantile(0.99)\n",
    "    daily_return = daily_return.clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "    return monthly_return, daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_data(returns: pd.DataFrame, factors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Match the data of returns and factors\n",
    "\n",
    "    :param returns: DataFrame with date as index, stocks as columns and return rates as values\n",
    "    :param factors_df: DataFrame with date as index, factors as columns and factor values as values\n",
    "    :return: DataFrame with same index\n",
    "    \"\"\"\n",
    "\n",
    "    returns = returns.loc[(returns.index >= factors_df.index[0]) & (returns.index <= factors_df.index[-1])]\n",
    "    factors_df = factors_df.loc[(factors_df.index >= returns.index[0]) & (factors_df.index <= returns.index[-1])]\n",
    "\n",
    "    returns, factors_df = returns.align(factors_df, join='outer', axis=0)\n",
    "    returns = returns.ffill()\n",
    "    factors_df = factors_df.ffill()\n",
    "    returns = returns.dropna()\n",
    "    factors_df = factors_df.dropna()\n",
    "    return returns, factors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(returns: pd.Series, factors: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform regression of returns on factors\n",
    "\n",
    "    :param returns: (n, ) Series with date as index and stock returns as values\n",
    "    :param factors: (n, k) DataFrame with date as index and factors as columns, 1 period lagged\n",
    "    :return: tuple of regression results\n",
    "    \"\"\"\n",
    "    X = factors.reset_index(drop=True)\n",
    "    y = returns.reset_index(drop=True)\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    summary_df = pd.DataFrame({\n",
    "        'coef': model.params,\n",
    "        'p_value': model.pvalues\n",
    "    })\n",
    "    summary_df = summary_df.iloc[1:]\n",
    "\n",
    "    significant = summary_df[summary_df['p_value'] < 0.05]\n",
    "    return significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_analysis(residuals: np.ndarray, lags=20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform residual analysis\n",
    "\n",
    "    :param residuals: array of residuals\n",
    "    :param lags: number of lags for the tests\n",
    "    :return: tuple of mean, variance and skewness\n",
    "    \"\"\"\n",
    "    # autocorrelation test\n",
    "    lb_result = acorr_ljungbox(residuals, lags=[lags], return_df=True).iloc[0]\n",
    "    \n",
    "    # ARCH test\n",
    "    arch_test = acorr_ljungbox(residuals**2, lags=[lags], return_df=True).iloc[0]\n",
    "\n",
    "    # normality test\n",
    "    shap = shapiro(residuals)\n",
    "    jb = jarque_bera(residuals)\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Test': ['Ljung-Box', 'ARCH', 'Shapiro-Wilk', 'Jarque-Bera'],\n",
    "        'Stat': [lb_result['lb_stat'], arch_test['lb_stat'], shap[0], jb[0]],\n",
    "        'p-value': [lb_result['lb_pvalue'], arch_test['lb_pvalue'], shap[1], jb[1]]\n",
    "    })\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "id": "ebc429a3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def garch_order(residuals: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    GARCH order selection using AIC\n",
    "    \n",
    "    \"\"\"\n",
    "    residuals = residuals \n",
    "    best_aic = np.inf\n",
    "    \n",
    "    best_order = (0, 0)\n",
    "    for p in range(1, 3):\n",
    "        for q in range(0, 3):\n",
    "            if p == 0 and q == 0:\n",
    "                continue\n",
    "            model = arch_model(residuals, vol='Garch', p=p, q=q, o=0, rescale=False)\n",
    "            results = model.fit(disp='off')\n",
    "            if results.aic < best_aic:\n",
    "                best_aic = results.aic\n",
    "                best_order = (p, q)\n",
    "    return best_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf5f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GARCH_M_FUNC(params: np.array, returns: pd.Series, factors: pd.DataFrame, p: int=1, q: int=1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    GARCH-M function\n",
    "    :param params: array of parameters\n",
    "    :param returns: (n, ) Series with date as index and stock returns as values\n",
    "    :param factors: (n, k) DataFrame with date as index and factors as columns, 1 period lagged\n",
    "    :param p: order of GARCH\n",
    "    :param q: order of ARCH\n",
    "    :return: tuple of residuals and conditional variance\n",
    "    \"\"\"\n",
    "    n = len(returns)\n",
    "    k = factors.shape[1]\n",
    "\n",
    "    alpha = params[0]\n",
    "    beta = params[1:k+1]\n",
    "    lambd = params[k+1]\n",
    "    omega = params[k+2]\n",
    "    a = params[k+3: k+3+p]\n",
    "    b = params[k+3+p: k+3+p+q]\n",
    "    if omega + sum(a) + sum(b) > 0.99:\n",
    "        return None, None\n",
    "    \n",
    "    # todo:  simply fill the first p and q values which are not accurate.\n",
    "    eps = np.zeros(n)\n",
    "    mean_return = returns.mean()\n",
    "    for t in range(max(p, q)):\n",
    "        eps[t] = returns.iloc[t] - mean_return\n",
    "    h = np.ones(n) * np.var(returns)\n",
    "    for t in range(max(p,q), n):\n",
    "        arch_sum = np.sum([a[i] * eps[t - i - 1]**2 for i in range(p)]) if p > 0 else 0\n",
    "        garch_sum = np.sum([b[j] * h[t - j - 1] for j in range(q)]) if q > 0 else 0\n",
    "        h[t] = omega + arch_sum + garch_sum\n",
    "\n",
    "        h[t] = np.clip(h[t], 1e-6, 1e6)\n",
    "        if k < 1:\n",
    "            eps[t] = returns.iloc[t] - alpha - lambd * np.sqrt(h[t])\n",
    "        else:\n",
    "            eps[t] = returns.iloc[t] - alpha - np.dot(beta, factors.iloc[t]) - lambd * np.sqrt(h[t])\n",
    "        eps[t] = np.clip(eps[t], -1e6, 1e6) \n",
    "    \n",
    "    eps = eps[max(p,q):]\n",
    "    h = h[max(p,q):]\n",
    "\n",
    "    return eps, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "id": "4eb6d638-6ce5-4a72-9a53-652e7243ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools.numdiff import approx_hess\n",
    "\n",
    "def compute_delta_tstats(params, likelihood_func, returns, factors_df, p, q):\n",
    "    \"\"\"\n",
    "    Fast t-stat computation via Hessian (delta method)\n",
    "    :param params: fitted parameters\n",
    "    :param likelihood_func: log-likelihood function\n",
    "    :return: std_errors, t_stats, p_values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hessian = approx_hess(params, lambda p_: likelihood_func(p_, returns, factors_df, p, q))\n",
    "        cov_matrix = np.linalg.pinv(hessian)\n",
    "        raw_vars = np.diag(cov_matrix)\n",
    "        fallback = np.nanmedian(raw_vars[raw_vars > 0]) if np.any(raw_vars > 0) else 1e-4\n",
    "        raw_vars = np.where(~np.isfinite(raw_vars) | (raw_vars < 1e-12), fallback, raw_vars)\n",
    "        std_errors = np.sqrt(raw_vars)\n",
    "        std_errors = np.clip(std_errors, 1e-6, 1e6)\n",
    "        t_stats = params / std_errors\n",
    "        t_stats = np.clip(t_stats, -100, 100)\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(t_stats)))\n",
    "\n",
    "        return std_errors, t_stats, p_values\n",
    "    except Exception as e:\n",
    "        print(\"Delta t-stat estimation failed:\", e)\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636be076-2a98-43f4-adea-ca80b8030d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garch_m_likelihood(params: np.ndarray, returns: pd.Series, factors: pd.DataFrame, p: int=1, q: int=1) -> float:\n",
    "    \"\"\"\n",
    "    GARCH-M likelihood function\n",
    "    :param params: array of parameters\n",
    "    :param returns: (n, ) Series with date as index and stock returns as values\n",
    "    :param factors: (n, k) DataFrame with date as index and factors as columns, 1 period lagged\n",
    "    :param p: order of GARCH\n",
    "    :param q: order of ARCH\n",
    "    :return: log-likelihood\n",
    "    \"\"\"\n",
    "    eps, h = GARCH_M_FUNC(params, returns, factors, p, q)\n",
    "    # add punishment to make sure the model is stationary\n",
    "    if eps is None:\n",
    "        return 1e6\n",
    "    loglik = 0\n",
    "    for t in range(0, len(eps)):\n",
    "        eps_sq = eps[t]**2\n",
    "        eps_sq_div_ht = eps_sq / max(h[t], 1e-6)   \n",
    "        eps_sq_div_ht = min(eps_sq_div_ht, 1e6)           \n",
    "        log_ht = np.log(max(h[t], 1e-6))                   \n",
    "\n",
    "        loglik += 0.5 * (log_ht + eps_sq_div_ht)\n",
    "    return loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd312811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_covariance(params: np.ndarray, returns: pd.Series, factors_df: pd.DataFrame, p: int=1, q: int=1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute robust covariance matrix for GARCH-M model\n",
    "    :param params: array of parameters\n",
    "    :param returns: (n, ) Series with date as index and stock returns as values\n",
    "    :param factors_df: (n, k) DataFrame with date as index and factors as columns, 1 period lagged\n",
    "    :param p: order of GARCH\n",
    "    :param q: order of ARCH\n",
    "    :return: covariance matrix of parameters\n",
    "    \"\"\"\n",
    "\n",
    "    hess_fn = nd.Hessian(lambda p_: garch_m_likelihood(p_, returns, factors_df, p, q))\n",
    "    hessian = hess_fn(params)\n",
    "    hessian_inv = np.linalg.pinv(hessian)\n",
    "\n",
    "    grad_fn = nd.Gradient(lambda p_: garch_m_likelihood(p_, returns, factors_df, p, q))\n",
    "    score = grad_fn(params).reshape(-1, 1)\n",
    "    S = score @ score.T\n",
    "    cov_matrix = hessian_inv @ S @ hessian_inv\n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "id": "a086cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wald_joint_test(params, cov_matrix, idx_list):\n",
    "    sub_params = params[idx_list]\n",
    "    sub_cov = cov_matrix[np.ix_(idx_list, idx_list)]\n",
    "    sub_cov_inv = np.linalg.pinv(sub_cov)\n",
    "    W = sub_params.T @ sub_cov_inv @ sub_params\n",
    "    p_value = 1 - chi2.cdf(W, df=len(idx_list))\n",
    "    return W, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d71cd1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def GARCHM(returns: pd.Series, factors_df: pd.DataFrame, p: int = 1, q: int = 1) -> tuple:\n",
    "    \"\"\"\n",
    "    GARCH-M model with multiple factors\n",
    "\n",
    "    :param returns: DataFrame with date as index, stocks as columns and close price as values\n",
    "    :param factors_df: DataFrame with date as index, factors as columns and factor values as values\n",
    "    :param p: order of GARCH\n",
    "    :param q: order of ARCH\n",
    "    :return: DataFrame with parameters, std_errors, t_stats, p_values and significant, and DataFrame with residual analysis\n",
    "    \"\"\"\n",
    "\n",
    "    k = factors_df.shape[1]\n",
    "    garch_params = [0.1] + [0.1/p if p != 0 else 0] * p + [0.7/(q) if q != 0 else 0] * q\n",
    "    mean_return = returns.mean()\n",
    "    init_params = np.array([mean_return] + [0.1]*k + [0.1] + garch_params)\n",
    "    bounds = [(None, None)] + [(None, None)] * k + [(None, None)] + [(0, None)] + [(0, 1)] * (p + q)\n",
    "    \n",
    "    # GARCH-M model\n",
    "    res = minimize(\n",
    "        garch_m_likelihood,\n",
    "        init_params,\n",
    "        args=(returns, factors_df, p, q),\n",
    "        bounds=bounds,\n",
    "        method='SLSQP',\n",
    "        options={'disp': True}\n",
    "    )\n",
    "    params = res.x\n",
    "\n",
    "    # Significance test\n",
    "    # std_errors, t_stats, p_values = compute_delta_tstats(\n",
    "    #     params, garch_m_likelihood, returns, factors_df, p, q\n",
    "    # )\n",
    "\n",
    "   \n",
    "    # try:\n",
    "    #     hess_fn = nd.Hessian(lambda p_: garch_m_likelihood(p_, returns, factors_df, p, q))\n",
    "    #     hessian = hess_fn(params)\n",
    "    \n",
    "    #     if not np.all(np.isfinite(hessian)):\n",
    "    #         raise ValueError(\"Hessian contains nan or inf.\")\n",
    "\n",
    "    #     try:\n",
    "    #         cov_matrix = np.linalg.pinv(hessian)\n",
    "    #     except np.linalg.LinAlgError:\n",
    "    #         raise ValueError(\"Hessian is too singular for pinv.\")\n",
    "\n",
    "    #     print(\"pre cov matrix\", cov_matrix)\n",
    "    #     cov_matrix = np.where(np.isnan(cov_matrix), 1e-6, cov_matrix) \n",
    "    #     cov_matrix = np.clip(cov_matrix, 1e-6, 1e6)\n",
    "    #     print(\"COV MATRIX\", cov_matrix)\n",
    "    #     std_errors = np.sqrt(np.diag(cov_matrix))\n",
    "    \n",
    "    # except Exception as e:\n",
    "    #     print(\"Switching to fallback: eigenvalue-regularized Hessian\")\n",
    "    #     hess_fn = nd.Hessian(lambda p_: garch_m_likelihood(p_, returns, factors_df, p, q))\n",
    "    #     hessian = hess_fn(params)\n",
    "    #     eigval, eigvec = np.linalg.eigh(hessian)\n",
    "    #     eigval[eigval < 1e-6] = 1e-6\n",
    "    #     hessian_reg = eigvec @ np.diag(eigval) @ eigvec.T\n",
    "\n",
    "    #     cov_matrix = np.linalg.inv(hessian_reg)\n",
    "    #     print(\"pre cov matrix\", cov_matrix)\n",
    "    #     cov_matrix = np.where(np.isnan(cov_matrix), 1e-6, cov_matrix) # fix unstable cov matrix\n",
    "    #     cov_matrix = np.clip(cov_matrix, 1e-6, 1e6)\n",
    "    #     print(\"COV MATRIX\", cov_matrix)\n",
    "    #     std_errors = np.sqrt(np.diag(cov_matrix))\n",
    "    cov_matrix = robust_covariance(params, returns, factors_df, p, q)\n",
    "    cov_matrix = np.where(np.isnan(cov_matrix), 1e-6, cov_matrix) # fix unstable cov matrix\n",
    "    cov_matrix = np.clip(cov_matrix, 1e-6, 1e6)\n",
    "    std_errors = np.sqrt(np.diag(cov_matrix))\n",
    "    std_errors = np.clip(std_errors, 1e-6, 1e6)\n",
    "    t_stats = params / std_errors\n",
    "    p_values = 2 * (1 - norm.cdf(np.abs(t_stats)))\n",
    "    \n",
    "\n",
    "    sector = ['intercept'] + ['factor'] * k + ['garch_m'] +\\\n",
    "             ['garch'] * (p + q + 1)\n",
    "    # Print results\n",
    "    param_names = (\n",
    "    ['alpha'] + factors_df.columns.tolist() +\n",
    "    ['lambda', 'omega'] +\n",
    "    [f'a_{i+1}' for i in range(p)] +\n",
    "    [f'b_{j+1}' for j in range(q)])\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'param': param_names,\n",
    "        'value': params,\n",
    "        'std_error': std_errors,\n",
    "        't_stat': t_stats,\n",
    "        'p_value': p_values,\n",
    "        'significant': p_values < 0.05,\n",
    "        'sector': sector\n",
    "    })\n",
    "\n",
    "    eps, h = GARCH_M_FUNC(params, returns, factors_df, p, q)\n",
    "\n",
    "    if eps is None:\n",
    "        print(\"Model is not stationary.\")\n",
    "        return None, None\n",
    "    else:\n",
    "        # residual analysis\n",
    "        print(\"Residual analysis...\")\n",
    "        h = np.clip(h, 1e-6, 1e6) # avoid zero and inf\n",
    "        standardized_residuals = np.clip(eps / np.sqrt(h), -1e6, 1e6)\n",
    "        dignose_result = residual_analysis(standardized_residuals)\n",
    "\n",
    "    return results_df, dignose_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188d7d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_data(stock_list=None) -> tuple:\n",
    "    \"\"\"\n",
    "    read stocks returns and factors data\n",
    "    :param stock_list: list of stocks. If None, read all stocks from ../data/raw/\n",
    "    :return: DataFrame of returns and factors\n",
    "    \"\"\"\n",
    "\n",
    "    factors = pd.read_csv('../data/hml.csv', index_col=0, header=0)\n",
    "\n",
    "    factors = factors.drop(\"AAPL\", axis=1)\n",
    "    factors.index = pd.to_datetime(factors.index, format='%Y-%m-%d')\n",
    "    \n",
    "    lower = factors.quantile(0.01)\n",
    "    upper = factors.quantile(0.99)\n",
    "    factors = factors.clip(lower=lower, upper=upper, axis=1) # delete abnormal numbers\n",
    "    \n",
    "    # return of stock\n",
    "    if stock_list is None:\n",
    "        df_returns = pd.DataFrame()\n",
    "        stocks = []\n",
    "        for dirpath, dirnames, filenames in os.walk('../data/raw/'):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith('.csv'):\n",
    "                    stocks.append(filename.split('.')[0])\n",
    "                    file_path = os.path.join(dirpath, filename)\n",
    "                    df = pd.read_csv(file_path, index_col=0, header=0)\n",
    "                    df.index = pd.to_datetime(df.index, format='%Y%m%d')\n",
    "                    df = df[['close']]\n",
    "                    df_returns = pd.concat([df_returns, df], axis=1, join='outer')\n",
    "        df_returns.columns = stocks\n",
    "    else:\n",
    "        df_returns = pd.DataFrame()\n",
    "        for stock in stock_list:\n",
    "            file_path = os.path.join('../data/raw/', stock + '.csv')\n",
    "            df = pd.read_csv(file_path, index_col=0, header=0)\n",
    "            df.index = pd.to_datetime(df.index, format='%Y%m%d')\n",
    "            df = df[['close']]\n",
    "            df_returns = pd.concat([df_returns, df], axis=1, join='outer')\n",
    "        df_returns.columns = stock_list\n",
    "\n",
    "\n",
    "    monthly_return, daily_return = return_process(df_returns)\n",
    "    \n",
    "    \n",
    "    # match the data\n",
    "    daily_return, factors_df = match_data(daily_return, factors)\n",
    "    \n",
    "    return daily_return, factors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849527b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_training(return_: pd.Series, factors_df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Analyze the data before training and decide order of GARCH model\n",
    "    :param return_: (n, )stock return data\n",
    "    :param factors_df: (n, k)factors data\n",
    "    :return: tuple of garch order , residual analysis and significant factors\n",
    "    \"\"\"\n",
    "\n",
    "    # regression\n",
    "    # beta, residuals = regression(return_, factors_df)\n",
    "\n",
    "    # residual analysis\n",
    "    test_result = residual_analysis(return_)\n",
    "    \n",
    "\n",
    "    # if test_result[test_result['Test'] == 'ARCH']['p-value'].values[0] > 0.1:\n",
    "    #     return 0, 0, test_result, []\n",
    "\n",
    "    # GARCH order selection\n",
    "    p, q = garch_order(return_)\n",
    "    print(f\"Best GARCH order: {p}, {q}\")\n",
    "\n",
    "    # significant factors\n",
    "    if len(factors_df) < 1: # when use pure garch with no factor \n",
    "        return p, q, test_result, []\n",
    "    else:\n",
    "        significant = regression(return_, factors_df)\n",
    "        significant_factors = significant.index.tolist()\n",
    "        return p, q, test_result, significant_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ef833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(return_: pd.Series, factors_df: pd.DataFrame, \n",
    "             p: int=1, q: int=1, backward=True) -> tuple:\n",
    "    \"\"\"\n",
    "    Training function\n",
    "    :param returns: DataFrame with date as index, stocks as columns and close price as values\n",
    "    :param factors_df: DataFrame with date as index, factors as columns and factor values as values\n",
    "    :param p: GARCH order\n",
    "    :param q: GARCH order\n",
    "    :param backward: whether to use backward selection. True, delete the insignificant factors and rerun. False, keep all factors\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # GARCH-M model\n",
    "    results_df, diagnose_result = GARCHM(return_, factors_df, p, q)\n",
    "    if results_df is None:\n",
    "        return None, None\n",
    "    if backward:\n",
    "        # backward selection\n",
    "        # check factors p-value\n",
    "        significant_factors = results_df[results_df['significant']]['param'].tolist()\n",
    "        significant_factors = [f for f in significant_factors if f in factors_df.columns]\n",
    "        if len(significant_factors) == len(factors_df.columns):\n",
    "            pass\n",
    "        else:\n",
    "            if len(significant_factors) == 0:\n",
    "                new_factor_df = pd.DataFrame()\n",
    "            else:\n",
    "                new_factor_df = factors_df[significant_factors]\n",
    "\n",
    "                # rerun the model with significant factors\n",
    "                results_df, diagnose_result = GARCHM(return_, new_factor_df, p, q)\n",
    "\n",
    "\n",
    "    return results_df, diagnose_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e459203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(returns: pd.Series, train_factors: pd.DataFrame, predict_factors: pd.DataFrame, model: pd.Series, p: int=1, q: int=1, predict_period=5, )-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict the future returns using GARCH-M model\n",
    "    :param returns: (n, ) stock return data\n",
    "    :param train_factors: (n, k) factors data in training period\n",
    "    :param predict_factors: (m, k) factors data in prediction period\n",
    "    :param model: params of factor + GARCH-M model\n",
    "    :param p: GARCH order\n",
    "    :param q: GARCH order\n",
    "    :param predict_period: number of periods to predict\n",
    "    :return: DataFrame with predicted returns and volatilities\n",
    "    \"\"\"\n",
    "    model = model.values\n",
    "    # get residuals and volatility\n",
    "    eps, h = GARCH_M_FUNC(model, returns, train_factors, p, q)\n",
    "\n",
    "    # predict\n",
    "    k = train_factors.shape[1]\n",
    "    alpha = model[0]\n",
    "    beta = model[1:k + 1]\n",
    "    lambd = model[k + 1]\n",
    "    omega = model[k + 2]\n",
    "    a = model[k + 3: k + 3 + p]\n",
    "    b = model[k + 3 + p: k + 3 + p + q]\n",
    "\n",
    "    forecasts = []\n",
    "    volatilities = []\n",
    "    \n",
    "    eps_extended = list(eps)\n",
    "    h_extended = list(h)\n",
    "    \n",
    "    for step in range(predict_period):\n",
    "        arch_sum = np.sum([a[i] * eps_extended[-i - 1] ** 2 for i in range(p)]) if p > 0 else 0\n",
    "        garch_sum = np.sum([b[j] * h_extended[-j - 1] for j in range(q)]) if q > 0 else 0\n",
    "        h_next = omega + arch_sum + garch_sum\n",
    "        h_next = max(h_next, 1e-6)\n",
    "\n",
    "        factor_input = predict_factors.iloc[step] if step < len(predict_factors) else predict_factors.iloc[-1]\n",
    "\n",
    "        r_next = alpha + (np.dot(beta, factor_input) if k > 0 else 0) + lambd * np.sqrt(h_next)\n",
    "        forecasts.append(r_next)\n",
    "        volatilities.append(h_next)\n",
    "        # update for next iteration\n",
    "        eps_extended.append(r_next - (alpha + (np.dot(beta, factor_input) if k > 0 else 0)))\n",
    "        h_extended.append(h_next)\n",
    "    return forecasts, volatilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_stock(return_: pd.Series, training_factors: pd.DataFrame, predict_factors: pd.DataFrame, predict_period=5) -> tuple:\n",
    "    \"\"\"\n",
    "    train and predict\n",
    "\n",
    "    :param return_: (n) stock return data\n",
    "    :param training_factors: (n,) factor values in training period\n",
    "    :param predict_factors: (m,) factor values in prediction period\n",
    "    :param predict_period: the number of days to predict\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Training...\")\n",
    "    p, q, test_result, significant_factors = pre_training(return_,training_factors) \n",
    "    if p == 0 and q == 0:\n",
    "        print(\"No Arch effect\")\n",
    "        return None, None, None, None, None\n",
    "    training_factors_stock = training_factors[significant_factors]\n",
    "    model_result, diagnose_result = training(return_, training_factors_stock, p, q, backward=True)\n",
    "    if model_result is None:\n",
    "        return None, None, None, None, None\n",
    "    else:\n",
    "        # if the model is not converged, skip\n",
    "        print(model_result)\n",
    "        current_factors = model_result[model_result['sector'] == 'factor']['param'].tolist()\n",
    "\n",
    "        # predict\n",
    "        training_factors_stock = training_factors[current_factors]\n",
    "        predict_factors_stock = predict_factors[current_factors]\n",
    "        print(\"Predicting...\")\n",
    "        r_next, h_next = predict(return_, training_factors_stock, predict_factors_stock, model_result['value'], p, q, predict_period) \n",
    "\n",
    "        return r_next, h_next, model_result, test_result, diagnose_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "id": "ee81cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(training_factors: pd.DataFrame, predict_factors: pd.DataFrame, returns: pd.DataFrame, predict_period=5):\n",
    "    \"\"\"\n",
    "    predict the next month return of stocks\n",
    "    :param training_factors: (n,) DataFrame with date as index, factors as columns and factor values as values\n",
    "    :param predict_factors: (m,) DataFrame with date as index, factors as columns and factor values as values\n",
    "    :param returns: (n,) DataFrame with date as index, stocks as columns and close price as values\n",
    "    :param predict_period: the number of days to predict\n",
    "    :return: (predict_period,) DataFrame with date as index, stocks as columns and close price as values\n",
    "    \"\"\"\n",
    "    predict_returns = pd.DataFrame(columns=returns.columns, index=range(predict_period))\n",
    "    predict_volatility = pd.DataFrame(columns=returns.columns, index=range(predict_period))\n",
    "    training_info = {}\n",
    "    valid_stocks = []\n",
    "    for stock in returns.columns:\n",
    "        print(f\"Predicting {stock}...\")\n",
    "        return_ = returns[stock]\n",
    "        r_next, h_next, model_result, test_result, diagnose_result = main_stock(return_, training_factors, predict_factors, predict_period)\n",
    "        if model_result is None:\n",
    "            print(f\"Model for {stock} is not converged.\")\n",
    "            continue\n",
    "\n",
    "        predict_returns[stock] = r_next\n",
    "        predict_volatility[stock] = h_next\n",
    "        training_info[stock] = {\"model\": model_result,\n",
    "                                \"test_result\": test_result,\n",
    "                                \"diagnose_result\": diagnose_result}\n",
    "        valid_stocks.append(stock)\n",
    "        print(\"Predicting finished.\")\n",
    "\n",
    "\n",
    "    return predict_returns, predict_volatility, training_info, valid_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1668,
   "id": "8d129fbe-6d3f-4923-b864-3ce48df59058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_stage_garch_m(returns: pd.Series, factors_df: pd.DataFrame, p: int = 1, q: int = 1):\n",
    "    \"\"\"\n",
    "    todo: try to separate factor model and GARCH-M and check if the result will be more stable\n",
    "    Two-stage estimation of a GARCH-M model:\n",
    "    1. OLS factor regression\n",
    "    2. GARCH(p, q) on residuals\n",
    "    3. Final regression: returns ~ factors + conditional volatility\n",
    "\n",
    "    Returns:\n",
    "        - final regression summary (with volatility term)\n",
    "        - GARCH model summary\n",
    "        - table with coefficients, t-stats, and p-values\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: OLS\n",
    "    X1 = factors_df.copy()\n",
    "    ols_model = sm.OLS(returns, X1).fit()\n",
    "    residuals = ols_model.resid\n",
    "\n",
    "    # Step 2:GARCH(p, q)\n",
    "    am = arch_model(residuals, vol='Garch', p=p, q=q, dist='normal')\n",
    "    garch_res = am.fit(disp=\"off\")\n",
    "    conditional_vol = garch_res.conditional_volatility\n",
    "\n",
    "    # Step 3\n",
    "    X2 = X1.copy()\n",
    "    X2[\"volatility\"] = conditional_vol\n",
    "    final_model = sm.OLS(returns, X2).fit()\n",
    "\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"param\": final_model.params.index,\n",
    "        \"value\": final_model.params.values,\n",
    "        \"t_stat\": final_model.tvalues,\n",
    "        \"p_value\": final_model.pvalues,\n",
    "        \"significant\": final_model.pvalues < 0.05\n",
    "    })\n",
    "\n",
    "    return final_model.summary(), garch_res.summary(), summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fab67-7476-4876-9e46-02dabf65d2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "id": "740ddd61",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def rolling_predict(factors_df: pd.DataFrame, returns: pd.DataFrame, training_period = 24, predict_period=5):\n",
    "    \"\"\"\n",
    "    rolling predict the next month return of stocks\n",
    "\n",
    "    :param factors_df: (n, )DataFrame with date as index, factors as columns and factor values as values\n",
    "    :param returns: (n, ) DataFrame with date as index, stocks as columns and close price as values\n",
    "    :param training_period: the number of days to train\n",
    "    :param fit_freq: the number of days to predict\n",
    "    \"\"\"\n",
    "    dates = returns.iloc[training_period:].index\n",
    "    predict_returns = pd.DataFrame(columns=returns.columns, index=dates)\n",
    "    predict_volatility = pd.DataFrame(columns=returns.columns, index=dates)\n",
    "    training_infos = {}\n",
    "    for i in range(0, len(dates)):\n",
    "        training_factors = factors_df.iloc[i:i + training_period]\n",
    "        predict_factors = factors_df.iloc[i + training_period:i + training_period + predict_period]\n",
    "        return_this = returns.iloc[i:i + training_period]\n",
    "        next_returns, next_vol, current_training, valid_stocks = batch_predict(training_factors, predict_factors, return_this)\n",
    "\n",
    "        predict_returns.iloc[i] = next_returns\n",
    "        predict_volatility.iloc[i] = next_vol\n",
    "        training_infos[dates[i]] = current_training \n",
    "        \n",
    "    return predict_returns, predict_volatility, training_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea231778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(start_date='2020-01-01', end_date='2024-12-31', save_path='../data/results', window=24, pure_garchm=False, stock_list=None):\n",
    "    \"\"\"\n",
    "    Main function\n",
    "\n",
    "    :param start_date: the first prediction date\n",
    "    :param end_date: the last prediction date\n",
    "    :window: the training period ( natural days )\n",
    "    :param pure_garchm: whether to use pure garch model\n",
    "    :param stock_list: the list of stocks to predict\n",
    "    :param fit_freq: the number of days to predict after training\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # read data\n",
    "    scale_ = 1  # to avoid training problems introduced by small scale\n",
    "    returns, factors_df = read_data(stock_list=stock_list)\n",
    "    returns = returns * scale_\n",
    "    factors_df = factors_df * scale_\n",
    "    # data begain date \n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    data_start_date = start_date - pd.DateOffset(days=window)\n",
    "\n",
    "    workday_window = len(returns.loc[data_start_date: start_date])\n",
    "\n",
    "    returns = returns.loc[data_start_date:end_date]\n",
    "    factors_df = factors_df.loc[data_start_date:end_date]\n",
    "\n",
    "    if pure_garchm:\n",
    "        factors_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # rolling predict\n",
    "    training_factors = factors_df.iloc[:workday_window]\n",
    "    predict_factors = factors_df.iloc[workday_window:]\n",
    "    predict_returns, predict_volatility, training_info, valid_stocks = batch_predict(training_factors, predict_factors, returns.iloc[:workday_window], predict_period=5)\n",
    "    print(predict_returns)\n",
    "    print(predict_volatility)\n",
    "    print(valid_stocks)\n",
    "    \n",
    "    # predict_returns, predict_volatility, training_info = rolling_predict(factors_df, returns, training_period=workday_window)\n",
    "\n",
    "    predict_returns = predict_returns / scale_\n",
    "    predict_volatility = predict_volatility / (scale_**2)\n",
    "    predict_returns = predict_returns.dropna(axis=1, how='all')\n",
    "    predict_volatility = predict_volatility.dropna(axis=1, how='all') # means there is no Arch effect\n",
    "    \n",
    "    # save results\n",
    "    predict_returns.to_csv(f'{save_path}/predict_returns.csv')\n",
    "    predict_volatility.to_csv(f'{save_path}/predict_volatility.csv')\n",
    "    \n",
    "\n",
    "    for date_ in training_info.keys():\n",
    "        for stock in training_info[date_].keys():\n",
    "            date_str = date_.strftime('%Y%m%d')\n",
    "            training_info[date_][stock]['model'].to_csv(f'{save_path}/details/training_info_{stock}_{date_str}.csv')\n",
    "            training_info[date_][stock]['test_result'].to_csv(f'{save_path}/details/test_result_{stock}_{date_str}.csv')\n",
    "            training_info[date_][stock]['diagnose_result'].to_csv(f'{save_path}/details/diagnose_result_{stock}_{date_str}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bb1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting CSCO...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -594.9774295984893\n",
      "            Iterations: 24\n",
      "            Function evaluations: 197\n",
      "            Gradient evaluations: 20\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -722.1702287032626\n",
      "            Iterations: 70\n",
      "            Function evaluations: 540\n",
      "            Gradient evaluations: 68\n",
      "Residual analysis...\n",
      "    param      value  std_error        t_stat   p_value  significant  \\\n",
      "0   alpha  -0.178149   0.018733 -9.509746e+00  0.000000         True   \n",
      "1     eqw   0.875903   0.003458  2.533167e+02  0.000000         True   \n",
      "2  lambda  18.285025  19.032081  9.607475e-01  0.336679        False   \n",
      "3   omega   0.000096   0.001000  9.560984e-02  0.923830        False   \n",
      "4     a_1   0.002719   0.001000  2.719404e+00  0.006540         True   \n",
      "5     b_1   0.000001   2.282693  4.808036e-07  1.000000        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2    garch_m  \n",
      "3      garch  \n",
      "4      garch  \n",
      "5      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting TROW...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -594.9774300216834\n",
      "            Iterations: 25\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 21\n",
      "Residual analysis...\n",
      "       param     value  std_error    t_stat   p_value  significant     sector\n",
      "0      alpha  0.001605   0.117534  0.013657  0.989104        False  intercept\n",
      "1   alpha003  0.012547   1.541737  0.008139  0.993506        False     factor\n",
      "2   alpha016  0.063328   0.084022  0.753708  0.451025        False     factor\n",
      "3   alpha029  0.164907   1.088122  0.151552  0.879541        False     factor\n",
      "4   alpha042  0.161275   1.300951  0.123967  0.901342        False     factor\n",
      "5   alpha045  0.036854   1.284637  0.028688  0.977113        False     factor\n",
      "6   alpha046 -0.001890   1.215306 -0.001555  0.998759        False     factor\n",
      "7        eqw  0.960809   0.592695  1.621085  0.104999        False     factor\n",
      "8     lambda -0.169888   3.834820 -0.044302  0.964664        False    garch_m\n",
      "9      omega  0.000970   0.001000  0.970244  0.331925        False      garch\n",
      "10       a_1  0.003748   0.105493  0.035525  0.971661        False      garch\n",
      "11       b_1  0.005708   0.533809  0.010692  0.991469        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting ISRG...\n",
      "Training...\n",
      "Best GARCH order: 2, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -654.0632307221655\n",
      "            Iterations: 42\n",
      "            Function evaluations: 368\n",
      "            Gradient evaluations: 41\n",
      "Residual analysis...\n",
      "    param         value  std_error        t_stat   p_value  significant  \\\n",
      "0   alpha -1.503716e-03   0.250438 -6.004356e-03  0.995209        False   \n",
      "1     eqw  9.325696e-01  12.985563  7.181587e-02  0.942748        False   \n",
      "2  lambda  3.730933e-01  36.054198  1.034812e-02  0.991744        False   \n",
      "3   omega  1.145145e-04   0.531444  2.154778e-04  0.999828        False   \n",
      "4     a_1  1.687453e-11   2.243131  7.522757e-12  1.000000        False   \n",
      "5     a_2  8.069007e-01  50.338643  1.602945e-02  0.987211        False   \n",
      "6     b_1  1.333843e-03   9.321710  1.430899e-04  0.999886        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2    garch_m  \n",
      "3      garch  \n",
      "4      garch  \n",
      "5      garch  \n",
      "6      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting NVR...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -513.0980656646343\n",
      "            Iterations: 23\n",
      "            Function evaluations: 204\n",
      "            Gradient evaluations: 19\n",
      "Residual analysis...\n",
      "      param     value  std_error    t_stat   p_value  significant     sector\n",
      "0     alpha -0.000693   0.206326 -0.003360  0.997319        False  intercept\n",
      "1  alpha034  0.040047   3.071800  0.013037  0.989598        False     factor\n",
      "2  alpha086  0.208870   2.859790  0.073037  0.941777        False     factor\n",
      "3       eqw  0.830331   1.198407  0.692862  0.488396        False     factor\n",
      "4    lambda  0.015694   3.947094  0.003976  0.996827        False    garch_m\n",
      "5     omega  0.002646   0.001000  2.646373  0.008136         True      garch\n",
      "6       a_1  0.010621   2.615345  0.004061  0.996760        False      garch\n",
      "7       b_1  0.015788   0.989644  0.015953  0.987272        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting TPR...\n",
      "Training...\n",
      "Best GARCH order: 1, 2\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -413.7079864689164\n",
      "            Iterations: 29\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 25\n",
      "Residual analysis...\n",
      "       param     value  std_error    t_stat       p_value  significant  \\\n",
      "0      alpha -0.003743   0.008754 -0.427609  6.689362e-01        False   \n",
      "1   alpha017  0.026508   3.171065  0.008359  9.933302e-01        False   \n",
      "2   alpha029  0.142878   1.670171  0.085547  9.318267e-01        False   \n",
      "3   alpha044  0.099103   4.023356  0.024632  9.803486e-01        False   \n",
      "4   alpha054  0.035568   3.679088  0.009668  9.922865e-01        False   \n",
      "5   alpha084  0.255483   3.263783  0.078278  9.376068e-01        False   \n",
      "6        eqw  1.734973   0.916966  1.892081  5.848024e-02        False   \n",
      "7     lambda  0.073512   0.097181  0.756445  4.493822e-01        False   \n",
      "8      omega  0.007774   0.001000  7.774225  7.549517e-15         True   \n",
      "9        a_1  0.018503   0.279067  0.066304  9.471356e-01        False   \n",
      "10       b_1  0.022899   0.852873  0.026849  9.785801e-01        False   \n",
      "11       b_2  0.021436   0.096721  0.221624  8.246069e-01        False   \n",
      "\n",
      "       sector  \n",
      "0   intercept  \n",
      "1      factor  \n",
      "2      factor  \n",
      "3      factor  \n",
      "4      factor  \n",
      "5      factor  \n",
      "6      factor  \n",
      "7     garch_m  \n",
      "8       garch  \n",
      "9       garch  \n",
      "10      garch  \n",
      "11      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting DVN...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -352.49975363889376\n",
      "            Iterations: 27\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 23\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -623.3973661774056\n",
      "            Iterations: 19\n",
      "            Function evaluations: 125\n",
      "            Gradient evaluations: 15\n",
      "Residual analysis...\n",
      "    param         value  std_error    t_stat       p_value  significant  \\\n",
      "0   alpha -1.027478e-02   0.065313 -0.157316  8.749960e-01        False   \n",
      "1     eqw  1.219316e+00   0.226903  5.373730  7.712453e-08         True   \n",
      "2  lambda  2.786667e-01   2.716447  0.102585  9.182923e-01        False   \n",
      "3   omega  5.258109e-04   0.001000  0.525811  5.990196e-01        False   \n",
      "4     a_1  5.362795e-07   0.285982  0.000002  9.999985e-01        False   \n",
      "5     b_1  3.363927e-06   0.561926  0.000006  9.999952e-01        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2    garch_m  \n",
      "3      garch  \n",
      "4      garch  \n",
      "5      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting BA...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -566.0497466300425\n",
      "            Iterations: 21\n",
      "            Function evaluations: 235\n",
      "            Gradient evaluations: 17\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -529.7329584684795\n",
      "            Iterations: 20\n",
      "            Function evaluations: 138\n",
      "            Gradient evaluations: 16\n",
      "Residual analysis...\n",
      "    param     value  std_error    t_stat   p_value  significant     sector\n",
      "0   alpha -0.004840   0.034213 -0.141466  0.887501        False  intercept\n",
      "1     eqw  0.450646   1.105019  0.407817  0.683408        False     factor\n",
      "2  lambda  0.116549   0.809547  0.143968  0.885526        False    garch_m\n",
      "3   omega  0.001879   0.001000  1.879060  0.060236        False      garch\n",
      "4     a_1  0.005268   0.896167  0.005878  0.995310        False      garch\n",
      "5     b_1  0.011278   0.873082  0.012917  0.989694        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting VRTX...\n",
      "Training...\n",
      "Best GARCH order: 2, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -626.4964053945127\n",
      "            Iterations: 16\n",
      "            Function evaluations: 146\n",
      "            Gradient evaluations: 12\n",
      "Residual analysis...\n",
      "      param     value   std_error    t_stat   p_value  significant     sector\n",
      "0     alpha  0.000016    2.207613  0.000007  0.999994        False  intercept\n",
      "1  alpha005  0.070582   17.726667  0.003982  0.996823        False     factor\n",
      "2  alpha044  0.057989    1.361501  0.042592  0.966027        False     factor\n",
      "3  alpha046  0.152780   11.398691  0.013403  0.989306        False     factor\n",
      "4       eqw  0.267715   16.921747  0.015821  0.987377        False     factor\n",
      "5    lambda  0.011647  117.471276  0.000099  0.999921        False    garch_m\n",
      "6     omega  0.000364    0.035216  0.010339  0.991751        False      garch\n",
      "7       a_1  0.000145    3.654535  0.000040  0.999968        False      garch\n",
      "8       a_2  0.000143    2.642720  0.000054  0.999957        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting BRK...\n",
      "Training...\n",
      "Best GARCH order: 2, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -441.71690894269364\n",
      "            Iterations: 25\n",
      "            Function evaluations: 286\n",
      "            Gradient evaluations: 21\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -429.2319269002072\n",
      "            Iterations: 33\n",
      "            Function evaluations: 284\n",
      "            Gradient evaluations: 29\n",
      "Residual analysis...\n",
      "    param     value  std_error     t_stat   p_value  significant     sector\n",
      "0   alpha  0.068061   0.001000  68.061162  0.000000         True  intercept\n",
      "1     eqw  0.605912   0.393600   1.539410  0.123704        False     factor\n",
      "2  lambda -0.330910   0.746505  -0.443279  0.657564        False    garch_m\n",
      "3   omega  0.004328   0.001000   4.327806  0.000015         True      garch\n",
      "4     a_1  0.012076   1.258590   0.009595  0.992344        False      garch\n",
      "5     a_2  0.012083   2.143690   0.005636  0.995503        False      garch\n",
      "6     b_1  0.024949   0.124888   0.199768  0.841662        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting GILD...\n",
      "Training...\n",
      "Best GARCH order: 1, 2\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -333.63722284919237\n",
      "            Iterations: 29\n",
      "            Function evaluations: 250\n",
      "            Gradient evaluations: 25\n",
      "Residual analysis...\n",
      "    param     value  std_error     t_stat   p_value  significant     sector\n",
      "0   alpha -0.240080   0.409103  -0.586845  0.557308        False  intercept\n",
      "1     eqw  0.393159   0.326917   1.202626  0.229121        False     factor\n",
      "2  lambda  1.655021   3.710343   0.446056  0.655557        False    garch_m\n",
      "3   omega  0.018532   0.001000  18.532353  0.000000         True      garch\n",
      "4     a_1  0.091649   6.607528   0.013870  0.988933        False      garch\n",
      "5     b_1  0.069056   2.424376   0.028484  0.977276        False      garch\n",
      "6     b_2  0.064820   1.580097   0.041023  0.967278        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting EQIX...\n",
      "Training...\n",
      "Best GARCH order: 1, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -692.9704154414507\n",
      "            Iterations: 96\n",
      "            Function evaluations: 1294\n",
      "            Gradient evaluations: 94\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -659.6894883031925\n",
      "            Iterations: 38\n",
      "            Function evaluations: 280\n",
      "            Gradient evaluations: 35\n",
      "Residual analysis...\n",
      "      param     value  std_error    t_stat   p_value  significant     sector\n",
      "0     alpha -0.010747   0.063912 -0.168150  0.866465        False  intercept\n",
      "1  alpha033 -0.405351   3.173216 -0.127741  0.898354        False     factor\n",
      "2  alpha051  0.849466   0.242694  3.500152  0.000465         True     factor\n",
      "3    lambda  0.881805   4.736108  0.186188  0.852298        False    garch_m\n",
      "4     omega  0.000129   0.027062  0.004767  0.996196        False      garch\n",
      "5       a_1  0.519550   1.940036  0.267804  0.788850        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting TER...\n",
      "Training...\n",
      "Best GARCH order: 1, 2\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -353.7568135597721\n",
      "            Iterations: 28\n",
      "            Function evaluations: 305\n",
      "            Gradient evaluations: 24\n",
      "Residual analysis...\n",
      "      param     value  std_error     t_stat   p_value  significant     sector\n",
      "0     alpha -0.021223   0.001158 -18.330318  0.000000         True  intercept\n",
      "1  alpha001  0.179822   2.058598   0.087351  0.930392        False     factor\n",
      "2  alpha034  0.010449   3.380691   0.003091  0.997534        False     factor\n",
      "3  alpha086 -0.233271   7.743317  -0.030125  0.975967        False     factor\n",
      "4       eqw  1.078088   2.002115   0.538475  0.590249        False     factor\n",
      "5    lambda  0.182420   0.089512   2.037934  0.041557         True    garch_m\n",
      "6     omega  0.014984   0.001000  14.983698  0.000000         True      garch\n",
      "7       a_1  0.012082   0.189592   0.063726  0.949188        False      garch\n",
      "8       b_1  0.044954   1.004931   0.044733  0.964320        False      garch\n",
      "9       b_2  0.042276   0.086432   0.489120  0.624757        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting MDT...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -642.2594093930275\n",
      "            Iterations: 17\n",
      "            Function evaluations: 135\n",
      "            Gradient evaluations: 13\n",
      "Residual analysis...\n",
      "      param     value  std_error    t_stat   p_value  significant     sector\n",
      "0     alpha -0.004989   0.044198 -0.112878  0.910128        False  intercept\n",
      "1  alpha025  0.130380   2.340050  0.055717  0.955568        False     factor\n",
      "2  alpha060  0.052317   2.410214  0.021706  0.982682        False     factor\n",
      "3       eqw  0.322854   0.537838  0.600281  0.548319        False     factor\n",
      "4    lambda  0.213172   1.789764  0.119106  0.905191        False    garch_m\n",
      "5     omega  0.000522   0.001000  0.521660  0.601907        False      garch\n",
      "6       a_1  0.023011   0.536584  0.042884  0.965794        False      garch\n",
      "7       b_1  0.003108   0.922158  0.003370  0.997311        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting QRVO...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -392.77621922883634\n",
      "            Iterations: 25\n",
      "            Function evaluations: 307\n",
      "            Gradient evaluations: 21\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -498.47120303293036\n",
      "            Iterations: 29\n",
      "            Function evaluations: 217\n",
      "            Gradient evaluations: 25\n",
      "Residual analysis...\n",
      "    param     value  std_error    t_stat   p_value  significant     sector\n",
      "0   alpha -0.000590   0.068051 -0.008676  0.993078        False  intercept\n",
      "1     eqw  1.283319   0.415855  3.085977  0.002029         True     factor\n",
      "2  lambda -0.044950   1.426544 -0.031510  0.974863        False    garch_m\n",
      "3   omega  0.002300   0.001000  2.300006  0.021448         True      garch\n",
      "4     a_1  0.001677   0.038306  0.043782  0.965078        False      garch\n",
      "5     b_1  0.012084   0.643447  0.018780  0.985016        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting A...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -351.55015466648825\n",
      "            Iterations: 26\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 22\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -418.8448447157089\n",
      "            Iterations: 31\n",
      "            Function evaluations: 243\n",
      "            Gradient evaluations: 27\n",
      "Residual analysis...\n",
      "    param     value  std_error     t_stat       p_value  significant  \\\n",
      "0   alpha -0.046107   0.001295 -35.599690  0.000000e+00         True   \n",
      "1     eqw  0.932102   0.734598   1.268860  2.044909e-01        False   \n",
      "2  lambda  0.510624   0.224540   2.274093  2.296038e-02         True   \n",
      "3   omega  0.007724   0.001000   7.723831  1.132427e-14         True   \n",
      "4     a_1  0.109224   3.338067   0.032721  9.738972e-01        False   \n",
      "5     b_1  0.046488   0.941240   0.049391  9.606079e-01        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2    garch_m  \n",
      "3      garch  \n",
      "4      garch  \n",
      "5      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting MO...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -633.8907952938926\n",
      "            Iterations: 24\n",
      "            Function evaluations: 278\n",
      "            Gradient evaluations: 20\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -624.6570201970267\n",
      "            Iterations: 24\n",
      "            Function evaluations: 181\n",
      "            Gradient evaluations: 20\n",
      "Residual analysis...\n",
      "    param         value  std_error     t_stat   p_value  significant  \\\n",
      "0   alpha -8.857812e-03   0.036541  -0.242409  0.808464        False   \n",
      "1     eqw  2.523621e-01   0.013535  18.645263  0.000000         True   \n",
      "2  lambda  4.140044e-01   1.286118   0.321902  0.747527        False   \n",
      "3   omega  6.535807e-04   0.001000   0.653581  0.513382        False   \n",
      "4     a_1  5.550508e-07   0.151689   0.000004  0.999997        False   \n",
      "5     b_1  5.405545e-06   0.803801   0.000007  0.999995        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2    garch_m  \n",
      "3      garch  \n",
      "4      garch  \n",
      "5      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting SWKS...\n",
      "Training...\n",
      "Best GARCH order: 2, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -306.9180971574539\n",
      "            Iterations: 22\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 18\n",
      "Residual analysis...\n",
      "       param     value  std_error    t_stat       p_value  significant  \\\n",
      "0      alpha -0.339831  14.884561 -0.022831  9.817850e-01        False   \n",
      "1   alpha001  0.371488  22.841455  0.016264  9.870240e-01        False   \n",
      "2   alpha016 -0.047090  16.539808 -0.002847  9.977284e-01        False   \n",
      "3   alpha018  0.018970  28.537682  0.000665  9.994696e-01        False   \n",
      "4   alpha022 -0.114847  13.541167 -0.008481  9.932330e-01        False   \n",
      "5   alpha024 -0.048987  13.526928 -0.003621  9.971105e-01        False   \n",
      "6   alpha033  0.231731   4.843479  0.047844  9.618407e-01        False   \n",
      "7   alpha051 -0.043088   8.392804 -0.005134  9.959038e-01        False   \n",
      "8   alpha086 -0.053057  35.767967 -0.001483  9.988164e-01        False   \n",
      "9        eqw  1.623185   1.452575  1.117453  2.638006e-01        False   \n",
      "10    lambda  2.021573  86.593543  0.023346  9.813746e-01        False   \n",
      "11     omega  0.028912   0.005123  5.643571  1.665592e-08         True   \n",
      "12       a_1  0.014328   6.330984  0.002263  9.981943e-01        False   \n",
      "13       a_2  0.014328  22.619725  0.000633  9.994946e-01        False   \n",
      "\n",
      "       sector  \n",
      "0   intercept  \n",
      "1      factor  \n",
      "2      factor  \n",
      "3      factor  \n",
      "4      factor  \n",
      "5      factor  \n",
      "6      factor  \n",
      "7      factor  \n",
      "8      factor  \n",
      "9      factor  \n",
      "10    garch_m  \n",
      "11      garch  \n",
      "12      garch  \n",
      "13      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting MCHP...\n",
      "Training...\n",
      "Best GARCH order: 1, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -590.213854543053\n",
      "            Iterations: 18\n",
      "            Function evaluations: 189\n",
      "            Gradient evaluations: 14\n",
      "Residual analysis...\n",
      "      param     value  std_error    t_stat   p_value  significant     sector\n",
      "0     alpha -0.001165   0.411437 -0.002832  0.997741        False  intercept\n",
      "1  alpha001  0.421814   2.532520  0.166559  0.867717        False     factor\n",
      "2  alpha022 -0.304211   4.281752 -0.071048  0.943359        False     factor\n",
      "3  alpha055  0.056967   1.902317  0.029946  0.976110        False     factor\n",
      "4  alpha060  0.394088   1.587474  0.248249  0.803942        False     factor\n",
      "5  alpha086 -0.764389   5.361628 -0.142567  0.886633        False     factor\n",
      "6       eqw  1.780255   1.879496  0.947198  0.343538        False     factor\n",
      "7    lambda -0.056542  16.541819 -0.003418  0.997273        False    garch_m\n",
      "8     omega  0.000584   0.001000  0.584311  0.559011        False      garch\n",
      "9       a_1  0.090446   2.046847  0.044188  0.964754        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting CDNS...\n",
      "Training...\n",
      "Best GARCH order: 2, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -610.2691126728221\n",
      "            Iterations: 57\n",
      "            Function evaluations: 538\n",
      "            Gradient evaluations: 53\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -565.7883579227915\n",
      "            Iterations: 17\n",
      "            Function evaluations: 119\n",
      "            Gradient evaluations: 13\n",
      "Residual analysis...\n",
      "    param     value  std_error    t_stat   p_value  significant     sector\n",
      "0   alpha -0.000606   1.605165 -0.000378  0.999699        False  intercept\n",
      "1     eqw  1.302520   4.924115  0.264519  0.791380        False     factor\n",
      "2  lambda  0.013164  53.397088  0.000247  0.999803        False    garch_m\n",
      "3   omega  0.000940   0.015471  0.060756  0.951554        False      garch\n",
      "4     a_1  0.000371   9.547894  0.000039  0.999969        False      garch\n",
      "5     a_2  0.000371   2.558731  0.000145  0.999884        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting EIX...\n",
      "Training...\n",
      "Best GARCH order: 2, 2\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -631.368663383408\n",
      "            Iterations: 26\n",
      "            Function evaluations: 398\n",
      "            Gradient evaluations: 22\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -641.1886466977594\n",
      "            Iterations: 21\n",
      "            Function evaluations: 234\n",
      "            Gradient evaluations: 17\n",
      "Residual analysis...\n",
      "       param     value  std_error    t_stat   p_value  significant     sector\n",
      "0      alpha  0.003954   0.764899  0.005169  0.995876        False  intercept\n",
      "1   alpha033 -0.403735   0.124590 -3.240507  0.001193         True     factor\n",
      "2   alpha042  0.002804   0.206571  0.013574  0.989170        False     factor\n",
      "3   alpha047  0.498304   0.268995  1.852468  0.063959        False     factor\n",
      "4   alpha086  0.761326   0.282440  2.695534  0.007028         True     factor\n",
      "5     lambda -0.137547   0.089274 -1.540731  0.123382        False    garch_m\n",
      "6      omega  0.000426   0.001414  0.301437  0.763081        False      garch\n",
      "7        a_1  0.515454   0.790037  0.652442  0.514116        False      garch\n",
      "8        a_2  0.444045   0.330668  1.342874  0.179313        False      garch\n",
      "9        b_1  0.000934   0.151814  0.006154  0.995090        False      garch\n",
      "10       b_2  0.000919   0.120844  0.007601  0.993935        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting BBY...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -500.5986260644426\n",
      "            Iterations: 19\n",
      "            Function evaluations: 129\n",
      "            Gradient evaluations: 15\n",
      "Residual analysis...\n",
      "    param     value  std_error    t_stat   p_value  significant     sector\n",
      "0   alpha  0.012793   0.010435  1.225944  0.220220        False  intercept\n",
      "1     eqw  0.690885   0.460087  1.501640  0.133190        False     factor\n",
      "2  lambda -0.228339   0.297592 -0.767288  0.442910        False    garch_m\n",
      "3   omega  0.002770   0.001000  2.770328  0.005600         True      garch\n",
      "4     a_1  0.007969   0.330301  0.024125  0.980753        False      garch\n",
      "5     b_1  0.014786   0.855186  0.017289  0.986206        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting WBA...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -515.2133742632993\n",
      "            Iterations: 43\n",
      "            Function evaluations: 489\n",
      "            Gradient evaluations: 41\n",
      "Residual analysis...\n",
      "      param     value  std_error      t_stat       p_value  significant  \\\n",
      "0     alpha -0.003376   0.763841   -0.004420  9.964734e-01        False   \n",
      "1  alpha002  1.463016   0.251535    5.816349  6.014668e-09         True   \n",
      "2  alpha008 -2.420201   0.398162   -6.078439  1.213580e-09         True   \n",
      "3  alpha010  3.221155   0.021794  147.797039  0.000000e+00         True   \n",
      "4  alpha013  1.250726   0.466740    2.679705  7.368697e-03         True   \n",
      "5       eqw  1.364269   0.007183  189.928050  0.000000e+00         True   \n",
      "6    lambda -0.024448  23.933900   -0.001021  9.991850e-01        False   \n",
      "7     omega  0.001003   0.001000    1.003151  3.157879e-01        False   \n",
      "8       a_1  0.017604   0.067025    0.262643  7.928260e-01        False   \n",
      "9       b_1  0.000000   0.178332    0.000000  1.000000e+00        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2     factor  \n",
      "3     factor  \n",
      "4     factor  \n",
      "5     factor  \n",
      "6    garch_m  \n",
      "7      garch  \n",
      "8      garch  \n",
      "9      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting AJG...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -488.17810587709664\n",
      "            Iterations: 22\n",
      "            Function evaluations: 229\n",
      "            Gradient evaluations: 18\n",
      "Residual analysis...\n",
      "      param         value  std_error        t_stat   p_value  significant  \\\n",
      "0     alpha -4.508836e-03   0.020766 -2.171225e-01  0.828113        False   \n",
      "1  alpha005 -1.759680e-01   2.637665 -6.671353e-02  0.946810        False   \n",
      "2  alpha006  2.825347e-01   1.769898  1.596333e-01  0.873170        False   \n",
      "3  alpha035  2.235203e-01   3.367947  6.636693e-02  0.947086        False   \n",
      "4  alpha086  2.708742e-01   1.603117  1.689672e-01  0.865822        False   \n",
      "5       eqw  8.415611e-01   0.650692  1.293333e+00  0.195896        False   \n",
      "6    lambda  8.622158e-02   0.381714  2.258800e-01  0.821295        False   \n",
      "7     omega  3.666874e-03   0.001000  3.666874e+00  0.000246         True   \n",
      "8       a_1  4.597964e-07   1.390849  3.305868e-07  1.000000        False   \n",
      "9       b_1  1.800316e-05   1.007473  1.786962e-05  0.999986        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2     factor  \n",
      "3     factor  \n",
      "4     factor  \n",
      "5     factor  \n",
      "6    garch_m  \n",
      "7      garch  \n",
      "8      garch  \n",
      "9      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting DTE...\n",
      "Training...\n",
      "Best GARCH order: 2, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -730.6457925817458\n",
      "            Iterations: 53\n",
      "            Function evaluations: 993\n",
      "            Gradient evaluations: 51\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -618.3771610307648\n",
      "            Iterations: 30\n",
      "            Function evaluations: 286\n",
      "            Gradient evaluations: 26\n",
      "Residual analysis...\n",
      "      param     value  std_error    t_stat   p_value  significant     sector\n",
      "0     alpha  0.015708   0.035217  0.446039  0.655569        False  intercept\n",
      "1  alpha042  0.108612   0.148883  0.729517  0.465685        False     factor\n",
      "2  alpha086  0.377427   2.012615  0.187531  0.851245        False     factor\n",
      "3    lambda -0.567360   1.121231 -0.506016  0.612845        False    garch_m\n",
      "4     omega  0.000695   0.001000  0.694521  0.487355        False      garch\n",
      "5       a_1  0.000000   0.835327  0.000000  1.000000        False      garch\n",
      "6       a_2  0.000000   0.872101  0.000000  1.000000        False      garch\n",
      "7       b_1  0.000000   0.918527  0.000000  1.000000        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting C...\n",
      "Training...\n",
      "Best GARCH order: 2, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -673.7813810059195\n",
      "            Iterations: 40\n",
      "            Function evaluations: 505\n",
      "            Gradient evaluations: 38\n",
      "Residual analysis...\n",
      "       param     value  std_error    t_stat   p_value  significant     sector\n",
      "0      alpha  0.000820   0.129240  0.006343  0.994939        False  intercept\n",
      "1   alpha002 -0.885697   2.836315 -0.312270  0.754835        False     factor\n",
      "2   alpha003  0.068368   5.342073  0.012798  0.989789        False     factor\n",
      "3   alpha030 -0.548003   2.585073 -0.211988  0.832117        False     factor\n",
      "4   alpha045 -0.947890   0.543023 -1.745580  0.080884        False     factor\n",
      "5        eqw  1.407781   0.961659  1.463908  0.143219        False     factor\n",
      "6     lambda  0.006637   0.262145  0.025318  0.979801        False    garch_m\n",
      "7      omega  0.000103   0.074770  0.001373  0.998905        False      garch\n",
      "8        a_1  0.029287   0.521040  0.056208  0.955176        False      garch\n",
      "9        a_2  0.435858   6.927724  0.062915  0.949834        False      garch\n",
      "10       b_1  0.000000   3.441005  0.000000  1.000000        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting T...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -499.767068040298\n",
      "            Iterations: 21\n",
      "            Function evaluations: 202\n",
      "            Gradient evaluations: 17\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -564.3595265921417\n",
      "            Iterations: 23\n",
      "            Function evaluations: 172\n",
      "            Gradient evaluations: 19\n",
      "Residual analysis...\n",
      "    param         value  std_error        t_stat   p_value  significant  \\\n",
      "0   alpha  9.133221e-03   0.036506  2.501831e-01  0.802446        False   \n",
      "1     eqw  2.574762e-01   0.185025  1.391573e+00  0.164052        False   \n",
      "2  lambda -1.838951e-01   1.055588 -1.742111e-01  0.861700        False   \n",
      "3   omega  1.417188e-03   0.001000  1.417188e+00  0.156428        False   \n",
      "4     a_1  4.185289e-07   1.912757  2.188092e-07  1.000000        False   \n",
      "5     b_1  6.646671e-06   0.916768  7.250114e-06  0.999994        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2    garch_m  \n",
      "3      garch  \n",
      "4      garch  \n",
      "5      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting MGM...\n",
      "Training...\n",
      "Best GARCH order: 1, 2\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -551.5123139094612\n",
      "            Iterations: 25\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 21\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -520.9943615752651\n",
      "            Iterations: 24\n",
      "            Function evaluations: 196\n",
      "            Gradient evaluations: 20\n",
      "Residual analysis...\n",
      "    param     value  std_error    t_stat   p_value  significant     sector\n",
      "0   alpha -0.010833   0.018435 -0.587620  0.556787        False  intercept\n",
      "1     eqw  1.784399   0.545370  3.271907  0.001068         True     factor\n",
      "2  lambda  0.192289   0.539499  0.356422  0.721525        False    garch_m\n",
      "3   omega  0.002136   0.001000  2.136074  0.032673         True      garch\n",
      "4     a_1  0.006624   8.102945  0.000818  0.999348        False      garch\n",
      "5     b_1  0.006296  80.902889  0.000078  0.999938        False      garch\n",
      "6     b_2  0.005932  80.677549  0.000074  0.999941        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting HUM...\n",
      "Training...\n",
      "Best GARCH order: 1, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -521.1804652111775\n",
      "            Iterations: 17\n",
      "            Function evaluations: 131\n",
      "            Gradient evaluations: 13\n",
      "Residual analysis...\n",
      "      param     value  std_error    t_stat   p_value  significant     sector\n",
      "0     alpha -0.004674   0.042582 -0.109773  0.912589        False  intercept\n",
      "1  alpha002 -0.030821   1.500804 -0.020537  0.983615        False     factor\n",
      "2  alpha086  0.201232   1.264199  0.159177  0.873529        False     factor\n",
      "3       eqw  0.430555   0.394720  1.090786  0.275367        False     factor\n",
      "4    lambda  0.078889   0.971919  0.081168  0.935308        False    garch_m\n",
      "5     omega  0.001831   0.001000  1.831440  0.067035        False      garch\n",
      "6       a_1  0.001410   0.035509  0.039714  0.968321        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting APH...\n",
      "Training...\n",
      "Best GARCH order: 2, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -552.6801486555652\n",
      "            Iterations: 24\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 22\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -509.5271155884564\n",
      "            Iterations: 20\n",
      "            Function evaluations: 171\n",
      "            Gradient evaluations: 16\n",
      "Residual analysis...\n",
      "      param     value  std_error    t_stat   p_value  significant     sector\n",
      "0     alpha -0.003964   0.027472 -0.144304  0.885260        False  intercept\n",
      "1  alpha043  0.015379   1.169783  0.013147  0.989511        False     factor\n",
      "2  alpha050  0.006916   2.384876  0.002900  0.997686        False     factor\n",
      "3  alpha060  0.188398   3.048948  0.061791  0.950729        False     factor\n",
      "4    lambda  0.063577   0.730616  0.087019  0.930657        False    garch_m\n",
      "5     omega  0.001618   0.001000  1.617757  0.105715        False      garch\n",
      "6       a_1  0.000633   0.020138  0.031417  0.974937        False      garch\n",
      "7       a_2  0.000633   0.067478  0.009376  0.992519        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting SYY...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -628.7938484846787\n",
      "            Iterations: 22\n",
      "            Function evaluations: 235\n",
      "            Gradient evaluations: 18\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -527.7541872985806\n",
      "            Iterations: 22\n",
      "            Function evaluations: 160\n",
      "            Gradient evaluations: 18\n",
      "Residual analysis...\n",
      "    param     value  std_error    t_stat   p_value  significant     sector\n",
      "0   alpha -0.013052   0.013489 -0.967554  0.333267        False  intercept\n",
      "1     eqw  0.540886   0.723345  0.747757  0.454606        False     factor\n",
      "2  lambda  0.271378   0.382351  0.709762  0.477852        False    garch_m\n",
      "3   omega  0.002238   0.001000  2.237669  0.025243         True      garch\n",
      "4     a_1  0.026938   2.851275  0.009448  0.992462        False      garch\n",
      "5     b_1  0.013682   0.953068  0.014355  0.988546        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting MSI...\n",
      "Training...\n",
      "Best GARCH order: 2, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -491.2288574527345\n",
      "            Iterations: 22\n",
      "            Function evaluations: 337\n",
      "            Gradient evaluations: 18\n",
      "Residual analysis...\n",
      "       param     value  std_error    t_stat   p_value  significant     sector\n",
      "0      alpha -0.001524   0.036779 -0.041443  0.966943        False  intercept\n",
      "1   alpha009  0.077152   1.881188  0.041012  0.967286        False     factor\n",
      "2   alpha012  0.114103   1.492051  0.076474  0.939042        False     factor\n",
      "3   alpha016  0.052343   1.317839  0.039719  0.968317        False     factor\n",
      "4   alpha022  0.113583   0.926504  0.122593  0.902429        False     factor\n",
      "5   alpha030  0.152260   1.627562  0.093551  0.925466        False     factor\n",
      "6   alpha034  0.144681   1.886314  0.076700  0.938862        False     factor\n",
      "7   alpha045  0.140839   1.602597  0.087882  0.929970        False     factor\n",
      "8   alpha046  0.130154   1.421921  0.091534  0.927068        False     factor\n",
      "9   alpha084  0.137163   1.656305  0.082813  0.934000        False     factor\n",
      "10       eqw  0.340873   0.549837  0.619952  0.535289        False     factor\n",
      "11    lambda  0.055968   0.661527  0.084604  0.932577        False    garch_m\n",
      "12     omega  0.003341   0.001000  3.340706  0.000836         True      garch\n",
      "13       a_1  0.051714   0.443600  0.116578  0.907195        False      garch\n",
      "14       a_2  0.051979   0.119009  0.436763  0.662283        False      garch\n",
      "15       b_1  0.020131   0.988132  0.020373  0.983746        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting FCX...\n",
      "Training...\n",
      "Best GARCH order: 2, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -504.22224873822273\n",
      "            Iterations: 18\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 14\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -595.4119164211772\n",
      "            Iterations: 24\n",
      "            Function evaluations: 186\n",
      "            Gradient evaluations: 22\n",
      "Residual analysis...\n",
      "    param     value  std_error     t_stat   p_value  significant     sector\n",
      "0   alpha -0.001817   0.008630  -0.210578  0.833217        False  intercept\n",
      "1     eqw  1.520872   0.024151  62.973778  0.000000         True     factor\n",
      "2  lambda -0.016401   0.428067  -0.038315  0.969437        False    garch_m\n",
      "3   omega  0.000353   0.113754   0.003101  0.997526        False      garch\n",
      "4     a_1  0.000000   0.184600   0.000000  1.000000        False      garch\n",
      "5     a_2  0.113815   0.049104   2.317834  0.020458         True      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting ADM...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -410.71725594039015\n",
      "            Iterations: 35\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 31\n",
      "Residual analysis...\n",
      "    param     value  std_error      t_stat       p_value  significant  \\\n",
      "0   alpha -0.123570   0.001000 -123.570084  0.000000e+00         True   \n",
      "1     eqw  1.023362   2.512843    0.407253  6.838224e-01        False   \n",
      "2  lambda  1.285151   0.614433    2.091605  3.647382e-02         True   \n",
      "3   omega  0.008212   0.001000    8.212204  2.220446e-16         True   \n",
      "4     a_1  0.220106   7.654582    0.028755  9.770602e-01        False   \n",
      "5     b_1  0.081470   0.936766    0.086969  9.306959e-01        False   \n",
      "\n",
      "      sector  \n",
      "0  intercept  \n",
      "1     factor  \n",
      "2    garch_m  \n",
      "3      garch  \n",
      "4      garch  \n",
      "5      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting LH...\n",
      "Training...\n",
      "Best GARCH order: 2, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -649.3636946147652\n",
      "            Iterations: 24\n",
      "            Function evaluations: 223\n",
      "            Gradient evaluations: 20\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -323.43299257196537\n",
      "            Iterations: 28\n",
      "            Function evaluations: 234\n",
      "            Gradient evaluations: 24\n",
      "Residual analysis...\n",
      "    param     value   std_error    t_stat   p_value  significant     sector\n",
      "0   alpha  0.022523   42.979501  0.000524  0.999582        False  intercept\n",
      "1     eqw  0.205643    0.299193  0.687326  0.491877        False     factor\n",
      "2  lambda -0.149774  277.349238 -0.000540  0.999569        False    garch_m\n",
      "3   omega  0.020494    0.067399  0.304074  0.761072        False      garch\n",
      "4     a_1  0.087404   92.859398  0.000941  0.999249        False      garch\n",
      "5     a_2  0.087145   97.134358  0.000897  0.999284        False      garch\n",
      "6     b_1  0.148759    1.899927  0.078297  0.937591        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting LNT...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -605.5918626885597\n",
      "            Iterations: 24\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 20\n",
      "Residual analysis...\n",
      "       param         value  std_error        t_stat   p_value  significant  \\\n",
      "0      alpha  2.495975e-03   0.001000  2.495975e+00  0.012561         True   \n",
      "1   alpha001 -1.869111e-01   1.319622 -1.416398e-01  0.887365        False   \n",
      "2   alpha033 -2.574558e-01   2.704173 -9.520684e-02  0.924151        False   \n",
      "3   alpha042  2.274150e-01   0.861822  2.638770e-01  0.791875        False   \n",
      "4   alpha047  3.484840e-01   0.650411  5.357900e-01  0.592104        False   \n",
      "5   alpha055 -1.863980e-01   0.989758 -1.883269e-01  0.850620        False   \n",
      "6   alpha060 -2.140851e-01   1.373990 -1.558127e-01  0.876181        False   \n",
      "7   alpha086  7.469270e-01   1.209090  6.177595e-01  0.536734        False   \n",
      "8        eqw  8.331284e-01   0.592132  1.406998e+00  0.159428        False   \n",
      "9     lambda -6.131367e-02   0.030071 -2.038934e+00  0.041457         True   \n",
      "10     omega  8.852080e-04   0.001000  8.852080e-01  0.376044        False   \n",
      "11       a_1  5.694813e-11   0.351530  1.620010e-10  1.000000        False   \n",
      "12       b_1  5.789624e-06   0.985808  5.872973e-06  0.999995        False   \n",
      "\n",
      "       sector  \n",
      "0   intercept  \n",
      "1      factor  \n",
      "2      factor  \n",
      "3      factor  \n",
      "4      factor  \n",
      "5      factor  \n",
      "6      factor  \n",
      "7      factor  \n",
      "8      factor  \n",
      "9     garch_m  \n",
      "10      garch  \n",
      "11      garch  \n",
      "12      garch  \n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting BAC...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -660.2978127061077\n",
      "            Iterations: 20\n",
      "            Function evaluations: 182\n",
      "            Gradient evaluations: 16\n",
      "Residual analysis...\n",
      "      param     value  std_error    t_stat   p_value  significant     sector\n",
      "0     alpha  0.000914   1.640005  0.000557  0.999555        False  intercept\n",
      "1  alpha025  0.111267  12.525534  0.008883  0.992912        False     factor\n",
      "2  alpha086  0.292473  26.010804  0.011244  0.991029        False     factor\n",
      "3       eqw  1.296667   3.039634  0.426587  0.669681        False     factor\n",
      "4    lambda  0.007210  85.162512  0.000085  0.999932        False    garch_m\n",
      "5     omega  0.000372   0.087834  0.004235  0.996621        False      garch\n",
      "6       a_1  0.001501  30.596356  0.000049  0.999961        False      garch\n",
      "7       b_1  0.002207   5.528050  0.000399  0.999681        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting GPN...\n",
      "Training...\n",
      "Best GARCH order: 2, 0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -428.9570509462784\n",
      "            Iterations: 55\n",
      "            Function evaluations: 697\n",
      "            Gradient evaluations: 51\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -583.8480471867456\n",
      "            Iterations: 18\n",
      "            Function evaluations: 134\n",
      "            Gradient evaluations: 14\n",
      "Residual analysis...\n",
      "    param     value  std_error    t_stat   p_value  significant     sector\n",
      "0   alpha  0.001174   0.202978  0.005782  0.995387        False  intercept\n",
      "1     eqw  1.536882   0.181525  8.466518  0.000000         True     factor\n",
      "2  lambda -0.082011   6.872345 -0.011934  0.990479        False    garch_m\n",
      "3   omega  0.000882   0.001000  0.882458  0.377529        False      garch\n",
      "4     a_1  0.000331   0.423844  0.000781  0.999377        False      garch\n",
      "5     a_2  0.000331   0.252586  0.001310  0.998955        False      garch\n",
      "Predicting...\n",
      "Predicting finished.\n",
      "Predicting HUBB...\n",
      "Training...\n",
      "Best GARCH order: 1, 1\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -656.2377434983588\n",
      "            Iterations: 33\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 29\n",
      "Residual analysis...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -620.9521115946985\n",
      "            Iterations: 23\n",
      "            Function evaluations: 207\n",
      "            Gradient evaluations: 19\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(start_date='2024-12-24', end_date='2024-12-31', save_path='../data/results', window=252, pure_garchm=False, stock_list=None)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "FTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
